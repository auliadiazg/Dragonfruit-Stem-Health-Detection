{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Install library yang diperlukan\n",
    "Menginstal library PyTorch (torch), torchvision (untuk manipulasi dataset gambar), dan matplotlib (untuk visualisasi)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-04T14:55:36.088027Z",
     "iopub.status.busy": "2025-01-04T14:55:36.087820Z",
     "iopub.status.idle": "2025-01-04T14:55:40.290225Z",
     "shell.execute_reply": "2025-01-04T14:55:40.289391Z",
     "shell.execute_reply.started": "2025-01-04T14:55:36.088008Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (0.20.1)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (75.7.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torchvision) (2.2.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.3-cp312-cp312-win_amd64.whl.metadata (168 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in e:\\project stki\\dragonfruit detection\\dragonfruit\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading matplotlib-3.10.0-cp312-cp312-win_amd64.whl (8.0 MB)\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.3/8.0 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.8/8.0 MB 1.6 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 1.0/8.0 MB 1.7 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 1.6/8.0 MB 1.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 1.8/8.0 MB 1.7 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 2.4/8.0 MB 1.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 2.9/8.0 MB 1.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 3.7/8.0 MB 2.1 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 4.5/8.0 MB 2.3 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 5.2/8.0 MB 2.4 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 5.5/8.0 MB 2.5 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 6.0/8.0 MB 2.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.6/8.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 7.1/8.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.3/8.0 MB 2.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.6/8.0 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.0/8.0 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.3-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 1.0/2.2 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 1.6/2.2 MB 2.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.1/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.2 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
      "Downloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.3 kiwisolver-1.4.8 matplotlib-3.10.0 pyparsing-3.2.1\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Periksa ketersediaan GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:55:40.291428Z",
     "iopub.status.busy": "2025-01-04T14:55:40.291213Z",
     "iopub.status.idle": "2025-01-04T14:55:40.296939Z",
     "shell.execute_reply": "2025-01-04T14:55:40.296284Z",
     "shell.execute_reply.started": "2025-01-04T14:55:40.291410Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apakah GPU tersedia: False\n",
      "GPU yang digunakan: Tidak ada GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Apakah GPU tersedia:\", torch.cuda.is_available())\n",
    "print(\"GPU yang digunakan:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"Tidak ada GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mengimpor modul yang diperlukan untuk membangun, melatih, dan mengevaluasi model\n",
    "\n",
    "* torch dan torch.nn: Untuk membuat dan melatih jaringan saraf.\n",
    "* torch.optim: Untuk mengoptimalkan model.\n",
    "* datasets dan transforms: Untuk memuat dan memproses dataset gambar.\n",
    "* DataLoader: Untuk mengelola batch data.\n",
    "* matplotlib.pyplot: Untuk memvisualisasikan data atau hasil.\n",
    "* os: Untuk mengelola jalur file dan folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:55:40.299149Z",
     "iopub.status.busy": "2025-01-04T14:55:40.298924Z",
     "iopub.status.idle": "2025-01-04T14:55:40.310195Z",
     "shell.execute_reply": "2025-01-04T14:55:40.309579Z",
     "shell.execute_reply.started": "2025-01-04T14:55:40.299130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Cek data dan ukuran data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T14:59:17.824933Z",
     "iopub.status.busy": "2025-01-04T14:59:17.824602Z",
     "iopub.status.idle": "2025-01-04T14:59:24.540171Z",
     "shell.execute_reply": "2025-01-04T14:59:24.539336Z",
     "shell.execute_reply.started": "2025-01-04T14:59:17.824908Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: , Subfolders: 0, Files: 2\n",
      "Folder: test, Subfolders: 4, Files: 0\n",
      "Subfolder: test\\anthracnose, Files: 111\n",
      "Subfolder: test\\cactusvirusx, Files: 160\n",
      "Subfolder: test\\healthy, Files: 206\n",
      "Subfolder: test\\stemcanker, Files: 287\n",
      "Folder: train, Subfolders: 4, Files: 0\n",
      "Subfolder: train\\anthracnose, Files: 1502\n",
      "Subfolder: train\\cactusvirusx, Files: 1404\n",
      "Subfolder: train\\healthy, Files: 1913\n",
      "Subfolder: train\\stemcanker, Files: 1060\n",
      "Folder: valid, Subfolders: 4, Files: 0\n",
      "Subfolder: valid\\anthracnose, Files: 235\n",
      "Subfolder: valid\\cactusvirusx, Files: 82\n",
      "Subfolder: valid\\healthy, Files: 109\n",
      "Subfolder: valid\\stemcanker, Files: 1110\n",
      "\n",
      "Total images in subfolders: 8179\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define Paths\n",
    "data_dir = r'E:\\Project STKI\\Dataset\\common dragon fruit stem disease.v2i.folder'\n",
    "\n",
    "# Function to count files and folders recursively\n",
    "def count_files_and_folders(path):\n",
    "    folder_structure = {}\n",
    "    total_images = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        current_level = root.replace(data_dir, \"\").count(os.sep)\n",
    "        relative_path = root.replace(data_dir, \"\").strip(os.sep)\n",
    "        if current_level == 0:\n",
    "            folder_structure[relative_path] = {\"subfolders\": 0, \"files\": len(files)}\n",
    "        elif current_level == 1:\n",
    "            folder_structure[relative_path] = {\"subfolders\": len(dirs), \"files\": len(files)}\n",
    "        elif current_level == 2:\n",
    "            folder_structure[relative_path] = {\"files\": len(files)}\n",
    "            total_images += len(files)\n",
    "    \n",
    "    return folder_structure, total_images\n",
    "\n",
    "# Get folder structure and total images\n",
    "folder_structure, total_images = count_files_and_folders(data_dir)\n",
    "\n",
    "# Display results\n",
    "for folder, details in folder_structure.items():\n",
    "    if 'subfolders' in details:\n",
    "        print(f\"Folder: {folder}, Subfolders: {details['subfolders']}, Files: {details['files']}\")\n",
    "    else:\n",
    "        print(f\"Subfolder: {folder}, Files: {details['files']}\")\n",
    "\n",
    "print(f\"\\nTotal images in subfolders: {total_images}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocessing gambar\n",
    "\n",
    "* Resize: Mengubah ukuran gambar menjadi 224x224 piksel (format yang diterima oleh ResNet-50).\n",
    "* RandomHorizontalFlip dan RandomRotation: Augmentasi data untuk meningkatkan generalisasi model.\n",
    "* ToTensor: Mengubah gambar menjadi tensor.\n",
    "* Normalize: Normalisasi nilai piksel berdasarkan mean dan standar deviasi yang sama dengan dataset ImageNet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T12:59:32.626983Z",
     "iopub.status.busy": "2025-01-04T12:59:32.626630Z",
     "iopub.status.idle": "2025-01-04T12:59:32.632690Z",
     "shell.execute_reply": "2025-01-04T12:59:32.631652Z",
     "shell.execute_reply.started": "2025-01-04T12:59:32.626953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Data Transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Muat dataset\n",
    "**Dataset dibagi menjadi tiga bagian: train, valid, dan test.**\n",
    "* ImageFolder: Memuat dataset berdasarkan struktur folder.\n",
    "* DataLoader: Mengelola data dalam batch untuk efisiensi pelatihan.\n",
    "* dataset_sizes: Menyimpan jumlah sampel dalam dataset.\n",
    "* class_names: Menyimpan nama kelas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T12:59:46.243189Z",
     "iopub.status.busy": "2025-01-04T12:59:46.242846Z",
     "iopub.status.idle": "2025-01-04T12:59:48.696649Z",
     "shell.execute_reply": "2025-01-04T12:59:48.695952Z",
     "shell.execute_reply.started": "2025-01-04T12:59:46.243164Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load Datasets\n",
    "datasets_dict = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in ['train', 'valid', 'test']}\n",
    "dataloaders = {x: DataLoader(datasets_dict[x], batch_size=32, shuffle=True, num_workers=2) for x in ['train', 'valid', 'test']}\n",
    "dataset_sizes = {x: len(datasets_dict[x]) for x in ['train', 'valid']}\n",
    "class_names = datasets_dict['train'].classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T12:59:53.792911Z",
     "iopub.status.busy": "2025-01-04T12:59:53.792520Z",
     "iopub.status.idle": "2025-01-04T12:59:53.798319Z",
     "shell.execute_reply": "2025-01-04T12:59:53.797267Z",
     "shell.execute_reply.started": "2025-01-04T12:59:53.792879Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classes: ['anthracnose', 'cactusvirusx', 'healthy', 'stemcanker']\n",
      "Number of classes: 4\n"
     ]
    }
   ],
   "source": [
    "print(f\"Loaded classes: {datasets_dict['train'].classes}\")\n",
    "print(f\"Number of classes: {len(datasets_dict['train'].classes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Atur GPU\n",
    "Mengatur perangkat untuk pelatihan (cuda jika GPU tersedia, atau cpu jika tidak)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T12:59:59.173447Z",
     "iopub.status.busy": "2025-01-04T12:59:59.173095Z",
     "iopub.status.idle": "2025-01-04T12:59:59.179162Z",
     "shell.execute_reply": "2025-01-04T12:59:59.177533Z",
     "shell.execute_reply.started": "2025-01-04T12:59:59.173416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set Device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Transfer learning dan pelatihan model\n",
    "* Memuat model ResNet-50 pre-trained dari ImageNet.\n",
    "* Mengganti lapisan fully connected (FC) terakhir agar sesuai dengan jumlah kelas dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:00:02.733332Z",
     "iopub.status.busy": "2025-01-04T13:00:02.733032Z",
     "iopub.status.idle": "2025-01-04T13:00:03.358283Z",
     "shell.execute_reply": "2025-01-04T13:00:03.357602Z",
     "shell.execute_reply.started": "2025-01-04T13:00:02.733308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Project STKI\\Dragonfruit Detection\\dragonfruit\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "e:\\Project STKI\\Dragonfruit Detection\\dragonfruit\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to C:\\Users\\Aulia Diaz/.cache\\torch\\hub\\checkpoints\\resnet50-0676ba61.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "# Load ResNet-50 Pre-trained Model\n",
    "model = models.resnet50(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, len(class_names))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:00:17.695532Z",
     "iopub.status.busy": "2025-01-04T13:00:17.695226Z",
     "iopub.status.idle": "2025-01-04T13:00:17.700790Z",
     "shell.execute_reply": "2025-01-04T13:00:17.699758Z",
     "shell.execute_reply.started": "2025-01-04T13:00:17.695510Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define Loss Function and Optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:03:17.050446Z",
     "iopub.status.busy": "2025-01-04T13:03:17.050118Z",
     "iopub.status.idle": "2025-01-04T13:03:17.057673Z",
     "shell.execute_reply": "2025-01-04T13:03:17.056799Z",
     "shell.execute_reply.started": "2025-01-04T13:03:17.050424Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Training Function\n",
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=20):\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        for phase in ['train', 'valid']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:03:22.371818Z",
     "iopub.status.busy": "2025-01-04T13:03:22.371355Z",
     "iopub.status.idle": "2025-01-04T13:25:44.838362Z",
     "shell.execute_reply": "2025-01-04T13:25:44.836985Z",
     "shell.execute_reply.started": "2025-01-04T13:03:22.371761Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "----------\n",
      "train Loss: 0.2189 Acc: 0.9228\n",
      "valid Loss: 0.5293 Acc: 0.8184\n",
      "Epoch 2/20\n",
      "----------\n",
      "train Loss: 0.1210 Acc: 0.9609\n"
     ]
    }
   ],
   "source": [
    "# Train the Model\n",
    "trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:31:46.251383Z",
     "iopub.status.busy": "2025-01-04T13:31:46.251025Z",
     "iopub.status.idle": "2025-01-04T13:31:46.415102Z",
     "shell.execute_reply": "2025-01-04T13:31:46.414243Z",
     "shell.execute_reply.started": "2025-01-04T13:31:46.251357Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save the Model\n",
    "torch.save(trained_model.state_dict(), \"resnet50_dragonfruit.pth\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Evaluasi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-04T13:31:59.913910Z",
     "iopub.status.busy": "2025-01-04T13:31:59.913578Z",
     "iopub.status.idle": "2025-01-04T13:32:04.932931Z",
     "shell.execute_reply": "2025-01-04T13:32:04.931721Z",
     "shell.execute_reply.started": "2025-01-04T13:31:59.913883Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.9175\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the Model on Test Data\n",
    "model.eval()\n",
    "corrects = 0\n",
    "\n",
    "for inputs, labels in dataloaders['test']:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs, 1)\n",
    "    corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "test_acc = corrects.double() / len(datasets_dict['test'])\n",
    "print(f\"Test Accuracy: {test_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6423314,
     "sourceId": 10370078,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6423611,
     "sourceId": 10370478,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "dragonfruit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
